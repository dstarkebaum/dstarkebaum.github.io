import json
import os
import time
import sys
#import argparse
#import pandas as pd
#import itertools as it

# get input file from argument (1.5GB JSON)
json_file = sys.argv[1]
corpus_path = os.getcwd()+'/data/s2-corpus/'+json_file

# create directory if needed
if not os.path.exists('data/neo4j'):
    os.makedirs('data/neo4j')

# delimiter for CSV files
d = '|'

# eliminate newlines, quotations, delimiters, and extra white space
def clean(text):
    return text.replace(d,'').replace('\n','').replace('"','').replace("'",'').strip()
# turn a list into a CSV row
def format(list):
    return d.join(list)+'\n'
# generate a path string from a single file name
def path(file):
    return(os.getcwd()+"/data/neo4j/"+json_file+"_"+file)

# define paths of output files (csv)
papers_csv = path("papers.csv")
is_cited_by_csv = path("is_cited_by.csv")
cites_csv = path("cites.csv")

authors_csv = path("authors.csv")
has_author_csv = path("has_author.csv")
is_author_of_csv = path("is_author_of.csv")

#remove any existing files
for file in [papers_csv,
        is_cited_by_csv,
        cites_csv,
        authors_csv,
        has_author_csv,
        is_author_of_csv]:
    if os.path.exists(file):
        os.remove(file)

# Do NOT write the headers to each csv file
# Instead, a single header file will be saved separately
#
# papers_header = path("papers_header.csv")
# is_cited_by_header = path("is_cited_by_header.csv")
# cites_header = path("cites_header.csv")
#
# authors_header = path("authors_header.csv")
# has_author_header = path("has_author_header.csv")
# is_author_of_header = path("is_author_of_header.csv")
#
# if not os.path.exists(papers_header):
#     with open(papers_header, 'w') as papers_out:
#         papers_out.write(format(['id:ID','title','year:INT','doi']))
# if not os.path.exists(is_cited_by_header):
#     with open(is_cited_by_header,'w') as is_cited_by_out:
#         is_cited_by_out.write(format(['id:START_ID','is_cited_by_id:END_ID',':TYPE']))
# if not os.path.exists(cites_header):
#     with open(cites_header,'w') as cites_out:
#         cites_out.write(format(['id:START_ID','cites_id:END_ID',':TYPE']))
#
# if not os.path.exists(authors_header):
#     with open(authors_header,'w') as authors_out:
#         authors_out.write(format(['id:ID','name']))
# if not os.path.exists(has_author_header):
#     with open(has_author_header,'w') as has_author_out:
#         has_author_out.write(format(['paper_id:START_ID','author_id:END_ID',':TYPE']))
# if not os.path.exists(is_author_of_header):
#     with open(is_author_of_header,'w') as is_author_of_out:
#         is_author_of_out.write(format(['author_id:START_ID','paper_id:END_ID']))


# Print status to STDOUT
start_time = time.time()
print("Parsing: "+corpus_path)
print("Start time: "+time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time)))

# keep a count of the number of records parsed
count = 0

with open(corpus_path, 'r') as json_in, \
        open(papers_csv, 'w') as papers_out, \
        open(is_cited_by_csv,'w') as is_cited_by_out, \
        open(cites_csv,'w') as cites_out, \
        open(authors_csv,'w') as authors_out, \
        open(has_author_csv,'w') as has_author_out, \
        open(is_author_of_csv,'w') as is_author_of_out:

    # Parse each line of JSON, and write the appropriate fields
    # to each csv table
    for line in json_in:
        #if 10000 == count:
        #    break

        # test with 100 lines to start
        if count in [100, 1000, 10000, 100000, 500000]:
            print(str(count)+" records parsed after "+str(time.time() - start_time)+" seconds")
        count = count + 1

        #    break
        js_line = json.loads(line)
        id = clean(js_line['id'])
        title = clean(js_line['title'])
        doi = clean(js_line['doi'])
        #abstract = clean(js_line['paperAbstract'])

        # Note: js_line['s2Url'] is redundant
        # It can be generated by: https://semanticscholar.org/paper/'id'

        # some entries seem to be missing a year, so just use an empty string
        try:
            year = clean(str(js_line['year']))
        except KeyError:
            year = ''

        paper_record = [id,title,year,doi]#, abstract]
        papers_out.write(format(paper_record))

        # each JSON row conains a list of citations and authors
        is_cited_by_list = js_line['inCitations']
        cites_list = js_line['outCitations']
        authors_list = js_line['authors']

        # inCitations and outCitations need to go to their own tables
        for cit in is_cited_by_list:
            cit=clean(cit)
            is_cited_by_out.write(format([id,cit]))
        for cit_hex in cites_list:
            cit=clean(cit_hex)
            cites_out.write(format([id,cit]))

        # js_line['authors'] has a format like:
        # [{"name":"Huseyin Demirbilek","ids":["4800055"]},{"name":"Serhan KÃ¼peli","ids":["5942490"]}]
        # So apparently each name can be associated with multiple ids
        # We are only insterested in the first one, which should be unique
        for author in authors_list:

            # Some papers have no authors.
            # If there are no authors for a paper, skip to the next one
            if 0 == len(author['ids']):
                continue
            #print(author['ids'][0])
            #author_id_int = int(author['ids'][0])
            author_id = clean(author['ids'][0])
            author_name = clean(author['name'])

            authors_out.write(format([author_id,author_name]))
            has_author_out.write(format([id,author_id]))
            is_author_of_out.write(format([author_id,id]))

print(str(count)+" records written to csv after "+str(time.time() - start_time)+" seconds")
